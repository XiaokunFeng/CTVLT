# CTVLT
[ICASSP'25] Enhancing Vision-Language Tracking by Effectively Converting Textual Cues into Visual Cues
![89d6654fa289543ea58395090c0fabf](https://github.com/user-attachments/assets/0cf55c4f-75be-42a3-88a3-44b88bd1420d)

Schematic diagram of motivation and method paradigm innovation. (a): Comparison of training environments between vision-language trackers and foundation grounding models. (b): The severe scarcity of textual data limits the trackerâ€™s ability to understand text, making direct use of textual cues for guidance challenging. (c): Our core insight is to leverage the strong text-image alignment capabilities of foundation grounding models by first converting textual cues into visual cues that the tracker can easily interpret, and then using them to guide the tracker.
